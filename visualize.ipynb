{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 可视化整个模型中的输入输出，方便分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "#  预备工作：\n",
    "#  导入库\n",
    "#  加载配置文件\n",
    "#  加载模型，加载数据集\n",
    "#---------------------------------#\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#---------------------------------#\n",
    "#  load  configs and checkpoint \n",
    "#---------------------------------#\n",
    "import torch\n",
    "from configs.config import get_config\n",
    "from models.graphModel import GraphModel\n",
    "from utils.graphDataset import GraphDataset\n",
    "cfg = get_config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.JSON_PATH = r'configs\\train_MOT17.json'\n",
    "test_dataset = GraphDataset(cfg,'Validation',False)\n",
    "# raw_tra_graph,raw_det_graph,gt_matrix = test_dataset.__getitem__(2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=13\n",
    "# cfg.BT_DIRECTED = True\n",
    "# cfg.K_NEIGHBOR  = k\n",
    "# cfg.BT_SELF_LOOP= False\n",
    "model = GraphModel(cfg.MODEL_YAML_PATH)\n",
    "checkpoint = torch.load(r'model_weights\\DA_120epoch.pth',map_location='cpu')\n",
    "model.load_state_dict(checkpoint[\"model\"], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.edgeEncoder.bt_self_loop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.edgeEncoder.bt_self_loop,model.edgeEncoder.bt_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(0,len(test_dataset))):\n",
    "    raw_tra_graph,raw_det_graph,gt_matrix = test_dataset.__getitem__(i)\n",
    "    # print(raw_tra_graph.num_nodes)\n",
    "    if raw_det_graph.num_nodes == 1 or raw_tra_graph.num_nodes == 1:\n",
    "        print(i)\n",
    "        break\n",
    "raw_tra_graph,raw_det_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "def get_size_KB(obj, seen=None):\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size_KB(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size_KB(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size_KB(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size_KB(i, seen) for i in obj])\n",
    "    return size /1024\n",
    "\n",
    "get_size_KB(test_dataset.dets_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 轨迹图与检测图节点 原始像素可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "def scale_patch_to_0_1(patch):\n",
    "    \"\"\"将裁剪后的图像patch缩放到[0, 1]范围内\"\"\"\n",
    "    patch_max = torch.max(patch)\n",
    "    patch_min = torch.min(patch)\n",
    "    patch = (patch - patch_min) / (patch_max - patch_min)  # 确保像素值在 [0, 1] 范围\n",
    "    return patch \n",
    "# import torchvision.transforms.functional as F\n",
    "tra_obj_ims = raw_tra_graph.x\n",
    "num_tra    = tra_obj_ims.shape[0] \n",
    "num_rows = math.ceil(num_tra )\n",
    "fig, axs   = plt.subplots(num_rows, 4, figsize=(50, 20))\n",
    "# # plt.imshow(tra_obj_im)\n",
    "\n",
    "for i in range(num_tra):\n",
    "    row = i //4\n",
    "    col = i % 4\n",
    "    patch = scale_patch_to_0_1(tra_obj_ims[i])\n",
    "    # print(patch.shape)\n",
    "    axs[row,col].imshow(patch.permute(1,2,0).numpy())\n",
    "    axs[row,col].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_obj_ims = raw_det_graph.x\n",
    "num_tra    = det_obj_ims.shape[0] \n",
    "num_rows = math.ceil(num_tra / 4)\n",
    "fig, axs   = plt.subplots(num_rows, 4, figsize=(50, 20))\n",
    "# # plt.imshow(tra_obj_im)\n",
    "\n",
    "for i in range(num_tra):\n",
    "    row = i //4\n",
    "    col = i % 4\n",
    "    patch = scale_patch_to_0_1(det_obj_ims[i])\n",
    "    axs[row,col].imshow(patch.permute(1,2,0).numpy())\n",
    "    axs[row,col].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 轨迹图与检测图经过Node Encoder之后的热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_graph = model.nodeEncoder(raw_tra_graph.clone())\n",
    "det_graph = model.nodeEncoder(raw_det_graph.clone())\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F \n",
    "\n",
    "#---------------------------------#\n",
    "#  轨迹图\n",
    "#---------------------------------#\n",
    "\n",
    "\n",
    "node_embed = tra_graph.x\n",
    "cos_sim_matrix = F.cosine_similarity(node_embed.unsqueeze(0), node_embed.unsqueeze(1), dim=2)\n",
    "plt.figure(figsize=(8, 6))  # 设置热图大小\n",
    "# sns.heatmap(cos_sim_matrix.detach().numpy(), annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
    "sns.heatmap(cos_sim_matrix.detach().numpy(), cmap='coolwarm', cbar=True)\n",
    "\n",
    "# 添加标题\n",
    "plt.title(\"Cosine Similarity Matrix of Trajectory Nodes\")\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embed = det_graph.x\n",
    "cos_sim_matrix = F.cosine_similarity(node_embed.unsqueeze(0), node_embed.unsqueeze(1), dim=2)\n",
    "plt.figure(figsize=(8, 6))  # 设置热图大小\n",
    "# sns.heatmap(cos_sim_matrix.detach().numpy(), annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
    "sns.heatmap(cos_sim_matrix.detach().numpy(), cmap='coolwarm', cbar=True)\n",
    "\n",
    "# 添加标题\n",
    "plt.title(\"Cosine Similarity Matrix of detection Nodes\")\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 经过EdgeEncoder  完成图的构建之后，可视化图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_graph,tra_graph.edge_index,tra_graph.location_info[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_graph = model.edgeEncoder(tra_graph,model.k)\n",
    "det_graph = model.edgeEncoder(det_graph,model.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "#  带有边颜色的画图  不同K\n",
    "#---------------------------------#\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert your graph to NetworkX and prepare positions\n",
    "pos_dict = {}\n",
    "for idx, pos in enumerate(tra_graph.location_info[:, :2]):\n",
    "    pos_dict[idx] = pos.numpy()\n",
    "\n",
    "G_tra = to_networkx(tra_graph, to_undirected=False)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Draw nodes with better visualization parameters\n",
    "nx.draw_networkx_nodes(\n",
    "    G_tra,\n",
    "    pos=pos_dict,\n",
    "    node_size=200,  # Increase node size\n",
    "    # node_color='w',  # Set node color\n",
    ")\n",
    "\n",
    "# Draw edges with better visualization parameters\n",
    "edge_colors = ['m' if edge[1] == 0 else 'grey' for edge in G_tra.edges]\n",
    "nx.draw_networkx_edges(\n",
    "    G_tra,\n",
    "    pos=pos_dict,\n",
    "    width=1,  # Make edges thicker\n",
    "    edge_color=edge_colors,\n",
    "    arrows=True,  # Enable arrows\n",
    "    arrowsize=10,  # Increase arrow size\n",
    "    arrowstyle='-|>',  # Use a solid arrow style\n",
    ")\n",
    "\n",
    "# Draw labels with better visualization parameters\n",
    "nx.draw_networkx_labels(\n",
    "    G_tra,\n",
    "    pos=pos_dict,\n",
    "    font_size=10,  # Set font size for labels\n",
    "    # font_color='darkblue',  # Set font color for labels\n",
    ")\n",
    "\n",
    "plt.title(f'tra-graph (K: {model.k})', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert your graph to NetworkX and prepare positions\n",
    "pos_dict = {}\n",
    "for idx, pos in enumerate(tra_graph.location_info[:, :2]):\n",
    "    pos_dict[idx] = pos.numpy()\n",
    "\n",
    "G_tra = to_networkx(tra_graph, to_undirected=False)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Draw nodes and edges with better visualization parameters\n",
    "nx.draw(\n",
    "    G_tra,\n",
    "    pos=pos_dict,\n",
    "    with_labels=True,\n",
    "    node_size=200,  # Increase node size\n",
    "    # node_color='blue',  # Set node color\n",
    "    # edge_color='gray',  # Set edge color\n",
    "    width=1,  # Make edges thicker\n",
    "    font_size=10,  # Set font size for labels\n",
    "    font_color='darkblue',  # Set font color for labels\n",
    "    arrows=True,  # Enable arrows\n",
    "    arrowsize=10,  # Increase arrow size\n",
    "    arrowstyle='-|>',  # Use a solid arrow style\n",
    ")\n",
    "\n",
    "plt.title(f'tra-graph (nodes:{tra_graph.num_nodes})', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {}\n",
    "for idx , pos in enumerate(det_graph.location_info[:,:2]):\n",
    "    pos_dict[idx] = pos.numpy()\n",
    "\n",
    "G_det = to_networkx(det_graph, to_undirected=False)\n",
    "plt.figure(figsize=(5, 3))\n",
    "nx.draw(\n",
    "    G_det,\n",
    "    pos=pos_dict,\n",
    "    with_labels=True,\n",
    "    node_size=300,  # Increase node size\n",
    "    # node_color='blue',  # Set node color\n",
    "    # edge_color='gray',  # Set edge color\n",
    "    width=1,  # Make edges thicker\n",
    "    font_size=10,  # Set font size for labels\n",
    "    font_color='darkblue',  # Set font color for labels\n",
    "    arrows=True,  # Enable arrows\n",
    "    arrowsize=10,  # Increase arrow size\n",
    "    arrowstyle='-|>',  # Use a solid arrow style\n",
    ")\n",
    "\n",
    "# nx.draw(G_det,with_labels=True,pos=pos_dict)\n",
    "plt.title(f'det-graph(Nodes:{det_graph.num_nodes})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_graph,tra_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4  真值矩阵可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F \n",
    "\n",
    "plt.figure(figsize=(8, 6))  # 设置热图大小\n",
    "# sns.heatmap(cos_sim_matrix.detach().numpy(), annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
    "sns.heatmap(gt_matrix, annot=False, cmap='Blues', cbar=False, linewidths=0.5, square=True)\n",
    "\n",
    "# 添加标题\n",
    "plt.title(\"groundtruth matrix\")\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 graphconv可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "#  tra-graph first\n",
    "#---------------------------------#\n",
    "node_embedding = tra_graph.x\n",
    "edge_embedding = tra_graph.edge_attr\n",
    "edge_index     = tra_graph.edge_index\n",
    "\n",
    "node_embedding_sg1 = model.graphconvLayer.sg1Func(node_embedding,edge_index,edge_embedding)      # torch.Size([32, 32])\n",
    "node_embedding_sg2 = model.graphconvLayer.sg2Func(node_embedding_sg1,edge_index,edge_embedding)  # torch.Size([32, 64])\n",
    "node_embedding_sg3 = model.graphconvLayer.sg3Func(node_embedding_sg2,edge_index,edge_embedding)  # torch.Size([32, 96])\n",
    "\n",
    "\n",
    "node_embedding_dg1 = model.graphconvLayer.dg1Func(node_embedding_sg1,cfg.K_NEIGHBOR)  # torch.Size([32,64])\n",
    "node_embedding_dg2 = model.graphconvLayer.dg2Func(node_embedding_dg1,cfg.K_NEIGHBOR)  # torch.Size([32, 96])\n",
    "\n",
    "\n",
    "node_embedding_cat1  = torch.cat([node_embedding_sg1,node_embedding_dg1,node_embedding_dg2,\n",
    "                                    node_embedding_sg2,node_embedding_sg3],dim=1)     # torch.Size([32, 352])\n",
    "node_embedding_fuse1 = model.graphconvLayer.fuse1Func(node_embedding_cat1)  # torch.Size([32, 1024])\n",
    "node_embedding_cat2  = torch.cat([node_embedding_fuse1,node_embedding_cat1],dim=1)  # torch.Size([32, 1376])\n",
    "node_embedding_output_tra= model.graphconvLayer.fuse2Func(node_embedding_cat2)  # torch.Size([32, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 node_embedding_output 是你的嵌入向量\n",
    "embeddings = node_embedding_output_tra.cpu().detach().numpy()\n",
    "\n",
    "# 使用 t-SNE 进行降维\n",
    "tsne = TSNE(n_components=2, random_state=0,perplexity=5)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "plt.title('tra-graph after grapnconv')\n",
    "# 绘制嵌入向量\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "#  det-graph first\n",
    "#---------------------------------#\n",
    "node_embedding = det_graph.x\n",
    "edge_embedding = det_graph.edge_attr\n",
    "edge_index     = det_graph.edge_index\n",
    "\n",
    "node_embedding_sg1 = model.graphconvLayer.sg1Func(node_embedding,edge_index,edge_embedding)      # torch.Size([32, 32])\n",
    "node_embedding_sg2 = model.graphconvLayer.sg2Func(node_embedding_sg1,edge_index,edge_embedding)  # torch.Size([32, 64])\n",
    "node_embedding_sg3 = model.graphconvLayer.sg3Func(node_embedding_sg2,edge_index,edge_embedding)  # torch.Size([32, 96])\n",
    "\n",
    "\n",
    "node_embedding_dg1 = model.graphconvLayer.dg1Func(node_embedding_sg1,cfg.K_NEIGHBOR)  # torch.Size([32,64])\n",
    "node_embedding_dg2 = model.graphconvLayer.dg2Func(node_embedding_dg1,cfg.K_NEIGHBOR)  # torch.Size([32, 96])\n",
    "\n",
    "\n",
    "node_embedding_cat1  = torch.cat([node_embedding_sg1,node_embedding_dg1,node_embedding_dg2,\n",
    "                                    node_embedding_sg2,node_embedding_sg3],dim=1)     # torch.Size([32, 352])\n",
    "node_embedding_fuse1 = model.graphconvLayer.fuse1Func(node_embedding_cat1)  # torch.Size([32, 1024])\n",
    "node_embedding_cat2  = torch.cat([node_embedding_fuse1,node_embedding_cat1],dim=1)  # torch.Size([32, 1376])\n",
    "node_embedding_output_det= model.graphconvLayer.fuse2Func(node_embedding_cat2)  # torch.Size([32, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 node_embedding_output 是你的嵌入向量\n",
    "embeddings = node_embedding_output_det.cpu().detach().numpy()\n",
    "\n",
    "# 使用 t-SNE 进行降维\n",
    "tsne = TSNE(n_components=2, random_state=0,perplexity=5)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "plt.title('det-graph after grapnconv')\n",
    "# 绘制嵌入向量\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 匹配矩阵可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = torch.mm(node_embedding_output_tra,node_embedding_output_det.transpose(1,0))\n",
    "n1   = torch.norm(node_embedding_output_tra,dim=-1,keepdim=True)\n",
    "n2   = torch.norm(node_embedding_output_det,dim=-1,keepdim=True)\n",
    "cost = - corr / torch.mm(n1,n2.transpose(1,0))  \n",
    "\n",
    "# 2. Prepare the augmented cost matrix for Sinkhorn\n",
    "m , n = cost.shape\n",
    "bins0 = model.alpha.expand(m, 1)\n",
    "bins1 = model.alpha.expand(1, n)\n",
    "alpha = model.alpha.expand(1, 1)\n",
    "couplings = torch.cat([torch.cat([cost,bins0],dim=-1),\n",
    "                        torch.cat([bins1,alpha],dim=-1)],dim=0)\n",
    "# # norm  = 1 / (m+n)  \n",
    "a_aug = torch.full((m+1,),1,dtype=torch.float32) \n",
    "b_aug = torch.full((n+1,),1,dtype=torch.float32) \n",
    "# a = torch.full((m,),0.95,dtype=torch.float32) \n",
    "# b = torch.full((n,),0.95,dtype=torch.float32) \n",
    "# a_aug[-1] = 0.95\n",
    "# b_aug[-1] = 0.95\n",
    "\n",
    "# pred_mtx = self.sinkhornLayer(couplings,a_aug,b_aug,\n",
    "#                             self.sinkhorn_iters,torch.exp(self.eplison) + 0.03)\n",
    "\n",
    "\n",
    "# to original possibility space \n",
    "pred_mtx = model.sinkhornLayer(couplings,a_aug,b_aug,\n",
    "                            #   lambd_sink = torch.exp(self.eplison) + 0.03) * (m + n)\n",
    "                                lambd_sink = torch.exp(model.eplison) + 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))  # 设置热图大小\n",
    "sns.heatmap(pred_mtx[:,:].detach().numpy(), cmap='coolwarm', cbar=True)\n",
    "\n",
    "# 添加标题\n",
    "plt.title(\"affinity matrix\")\n",
    "\n",
    "# torch.sum(pred_mtx, dim=1),torch.sum(pred_mtx, dim=0),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.graphToolkit import hungarian\n",
    "\n",
    "match_mtx,match_idx,unmatch_tra,unmatch_det = hungarian(pred_mtx.detach(),0.5)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))  # 设置热图大小\n",
    "sns.heatmap(match_mtx[:-1,:-1], cmap='coolwarm', cbar=True)\n",
    "\n",
    "# 添加标题\n",
    "plt.title(\"assignment matrix\")\n",
    "\n",
    "# torch.sum(pred_mtx, dim=1),torch.sum(pred_mtx, dim=0),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "TP = np.sum(np.logical_and(match_mtx == 1, gt_matrix.numpy() == 1))\n",
    "FP = np.sum(np.logical_and(match_mtx == 1, gt_matrix.numpy() == 0))\n",
    "FN = np.sum(np.logical_and(match_mtx == 0, gt_matrix.numpy() == 1))\n",
    "\n",
    "# Precision\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "# Recall\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "# F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 假如用这个网络来分辨出跟踪的同一个目标，进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#---------------------------------#\n",
    "#  load  configs and checkpoint \n",
    "#---------------------------------#\n",
    "import torch\n",
    "from configs.config import get_config\n",
    "from models.graphModel import GraphModel\n",
    "from utils.graphDataset import GraphDataset\n",
    "cfg = get_config()\n",
    "model = GraphModel(cfg)\n",
    "# test_dataset = GraphDataset(cfg,'Train',True)\n",
    "# checkpoint = torch.load(r'experiments\\checkpoints\\latest.pth')\n",
    "checkpoint = torch.load(r'experiments\\checkpoints\\bestScore(1.0)_epoch(86).pth')\n",
    "model.load_state_dict(checkpoint[\"model\"], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 统计 在不同帧率下，同一目标移动的像素均值（包括 移动视角与静止视角）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "#  data - whole dataset [MOT17,MOT20,DanceTrack]\n",
    "#---------------------------------#\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lifespan = 9\n",
    "dataset_type = {\n",
    "    'MOT17': ['train'],\n",
    "    'MOT20': ['train'],\n",
    "    'DanceTrack': ['train','val']\n",
    "}\n",
    "# output_file = os.path.join(,'avgMovement.xlsx')\n",
    "output_folder = os.path.join('experiments','statisticalData','avgMovement',f'windowSize[{lifespan}]')\n",
    "os.makedirs(output_folder,exist_ok=True)\n",
    "output_result = {}\n",
    "maxvalue_list = []\n",
    "maxvalue_seq = []\n",
    "\n",
    "def calculate_average_movement(df, lifespan):\n",
    "    results = []\n",
    "\n",
    "    for id_, group in df.groupby('id'):\n",
    "        # 获取当前目标的中心点坐标\n",
    "        centers = group[['frame', 'center_x', 'center_y']].reset_index(drop=True)\n",
    "        n_frames = len(centers)\n",
    "\n",
    "        # 计算每个lifespan范围内的均值\n",
    "        for start_frame in range(1, n_frames - lifespan + 1):\n",
    "            end_frame = start_frame + lifespan - 1\n",
    "            sub_group = centers[(centers['frame'] >= start_frame) & (centers['frame'] <= end_frame)]\n",
    "\n",
    "            # 计算x, y坐标的平均移动距离\n",
    "            displacements = np.sqrt(\n",
    "                (sub_group['center_x'].diff().iloc[1:].values ** 2) + (sub_group['center_y'].diff().iloc[1:].values ** 2)\n",
    "            )\n",
    "            avg_displacement = displacements.mean() if len(displacements) > 0 else 0\n",
    "            results.append({'id': id_, 'frame_range': f'{start_frame}-{end_frame}', 'avg_displacement': avg_displacement})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "for dataset in dataset_type.keys():\n",
    "    for sub_folder in dataset_type[dataset]:\n",
    "        sub_folder_path = os.path.join('datasets',dataset,sub_folder)\n",
    "        maxvalue_seq = []\n",
    "        for seq in os.listdir(sub_folder_path):\n",
    "            if not os.path.isdir(os.path.join(sub_folder_path,seq)):\n",
    "                 continue\n",
    "            gt_path   = os.path.join(sub_folder_path,seq,'gt','gt.txt')\n",
    "            info_path = os.path.join(sub_folder_path,seq,'seqinfo.ini')\n",
    "            with open(info_path,'r') as f:\n",
    "                lines_split = [ l.split('=') for l in f.read().splitlines()[1:]]\n",
    "                info_dict  = dict(s for s in lines_split if isinstance(s,list) and len(s) == 2)\n",
    "            print(f\"seq[{seq}] info: framerate[{info_dict['frameRate']}], height[{info_dict['imHeight']}], width[{info_dict['imWidth']}]\")\n",
    "            data = np.loadtxt(gt_path,delimiter=',')\n",
    "            df = pd.DataFrame(data, columns=['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height', 'ignore1', 'obj_type', 'ignore3'])\n",
    "            df = df[df['obj_type'].isin([1,2,7])]\n",
    "            df['center_x'] = df['bb_left'] + df['bb_width']  / 2\n",
    "            df['center_y'] = df['bb_top']  + df['bb_height'] / 2\n",
    "            df = df.sort_values(by=['id', 'frame'])\n",
    "\n",
    "            result = calculate_average_movement(df, lifespan)\n",
    "\n",
    "            output_result[seq] = result[result['avg_displacement'] != 0]\n",
    "            meanvalue = result[result['avg_displacement'] != 0].groupby('id')['avg_displacement'].mean().mean()\n",
    "            maxvalue  = result[result['avg_displacement'] != 0].groupby('id')['avg_displacement'].max().max()\n",
    "            maxvalue_seq.append(maxvalue)\n",
    "            maxvalue_list.append(maxvalue)\n",
    "            print(f\"seq[{seq}] mean movement:[{meanvalue:.4f}], max movement:[{maxvalue:.4f}] \")\n",
    "    #         break\n",
    "        # break\n",
    "    # break\n",
    "        # 绘制当前序列的最大移动距离柱状图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        mean_value = np.mean(maxvalue_seq)\n",
    "        plt.bar(range(len(maxvalue_seq)), maxvalue_seq, color='blue',label='Max Movement')\n",
    "        for i, v in enumerate(maxvalue_seq):\n",
    "            plt.text(i, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "        plt.axhline(y=mean_value, color='r', linestyle='--',label=f'mean:{mean_value:.2f}') \n",
    "        # plt.text(len(maxvalue_seq) - 1, mean_value, f'Mean: {mean_value:.2f}', ha='right', va='bottom')  # 标注均值\n",
    "        # plt.xlabel('Sequence')\n",
    "        plt.legend()\n",
    "        plt.ylabel('Max Movement')\n",
    "        plt.title(f'Max Movement for Sequence {dataset}({sub_folder}) || WindowSize {lifespan}')\n",
    "        plt.xticks(range(len(maxvalue_seq)), [f'Seq {i}' for i in range(1, len(maxvalue_seq) + 1)])\n",
    "        plt.savefig(os.path.join(output_folder,f'maxMovement_{dataset}({sub_folder})-Window_{lifespan}.png'))\n",
    "        plt.close()\n",
    "plt.figure(figsize=(10, 6))\n",
    "mean_value = np.mean(maxvalue_list)\n",
    "plt.bar(range(len(maxvalue_list)), maxvalue_list, color='green',label='Max Movement')\n",
    "for i, v in enumerate(maxvalue_list):\n",
    "    plt.text(i, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "plt.axhline(y=mean_value, color='r', linestyle='--',label=f'mean:{mean_value:.2f}') \n",
    "# plt.text(len(maxvalue_list) - 1, mean_value, f'Mean: {mean_value:.2f}', ha='right', va='bottom')  # 标注均值\n",
    "# plt.xlabel('Sequence')\n",
    "plt.legend()\n",
    "plt.ylabel('Max Movement')\n",
    "plt.title(f'Max Movement for All Sequences || WindowSize {lifespan}')\n",
    "plt.xticks(range(len(maxvalue_list)), [f'Seq {i}' for i in range(1, len(maxvalue_list) + 1)])\n",
    "plt.savefig(os.path.join(output_folder,f'maxMovement_all-Window_{lifespan}.png'))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# so large file that cannot save \n",
    "# output_df = pd.concat(output_result.values(), keys=output_result.keys())\n",
    "# output_df.to_excel(output_file)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lifespan remains defined but is not used in the updated context\n",
    "lifespan = 9\n",
    "dataset_type = {\n",
    "    'MOT17': ['train'],\n",
    "    'MOT20': ['train'],\n",
    "    'DanceTrack': ['train', 'val']\n",
    "}\n",
    "\n",
    "output_folder = os.path.join('experiments', 'statisticalData', 'targetCounts')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_result = {}\n",
    "\n",
    "def calculate_frame_target_counts(df):\n",
    "    # Group by frame and count the number of unique IDs (targets) in each frame\n",
    "    frame_counts = df.groupby('frame')['id'].nunique()\n",
    "    return frame_counts\n",
    "\n",
    "# Initialize lists to store overall statistics for all datasets\n",
    "all_mean_values = []\n",
    "all_max_values = []\n",
    "all_min_values = []\n",
    "\n",
    "for dataset in dataset_type.keys():\n",
    "    dataset_mean_values = []\n",
    "    dataset_max_values = []\n",
    "    dataset_min_values = []\n",
    "\n",
    "    for sub_folder in dataset_type[dataset]:\n",
    "        sub_folder_path = os.path.join('datasets', dataset, sub_folder)\n",
    "        seq_stats = []\n",
    "\n",
    "        for seq in os.listdir(sub_folder_path):\n",
    "            if not os.path.isdir(os.path.join(sub_folder_path, seq)):\n",
    "                continue\n",
    "\n",
    "            gt_path = os.path.join(sub_folder_path, seq, 'gt', 'gt.txt')\n",
    "            info_path = os.path.join(sub_folder_path, seq, 'seqinfo.ini')\n",
    "\n",
    "            with open(info_path, 'r') as f:\n",
    "                lines_split = [l.split('=') for l in f.read().splitlines()[1:]]\n",
    "                info_dict = dict(s for s in lines_split if isinstance(s, list) and len(s) == 2)\n",
    "\n",
    "            # print(f\"seq[{seq}] info: framerate[{info_dict['frameRate']}], height[{info_dict['imHeight']}], width[{info_dict['imWidth']}]\")\n",
    "            data = np.loadtxt(gt_path, delimiter=',')\n",
    "            df = pd.DataFrame(data, columns=['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height', 'ignore1', 'obj_type', 'ignore3'])\n",
    "            df = df[df['obj_type'].isin([1, 2, 7])]\n",
    "            df = df.sort_values(by=['id', 'frame'])\n",
    "\n",
    "            # Calculate frame target counts\n",
    "            frame_counts = calculate_frame_target_counts(df)\n",
    "\n",
    "            # Compute statistics for the current sequence\n",
    "            mean_value = frame_counts.mean()\n",
    "            max_value = frame_counts.max()\n",
    "            min_value = frame_counts.min()\n",
    "\n",
    "            dataset_mean_values.append(mean_value)\n",
    "            dataset_max_values.append(max_value)\n",
    "            dataset_min_values.append(min_value)\n",
    "\n",
    "            seq_stats.append({'seq': seq, 'mean': mean_value, 'max': max_value, 'min': min_value})\n",
    "\n",
    "            # print(f\"seq[{seq}] mean targets per frame: [{mean_value:.4f}], max targets: [{max_value:.4f}], min targets: [{min_value:.4f}]\")\n",
    "\n",
    "            # Plot histogram of frame target counts for the current sequence\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(frame_counts, bins=20, color='blue', alpha=0.7, label='Frame Target Counts')\n",
    "            plt.axvline(mean_value, color='r', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "            plt.xlabel('Number of Targets per Frame')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.title(f'Target Count Distribution for {dataset} - {sub_folder} - {seq}')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(output_folder, f'{dataset}_{sub_folder}_{seq}_target_count_histogram.png'))\n",
    "            plt.close()\n",
    "\n",
    "        # Save per-sequence statistics to a CSV file\n",
    "        seq_stats_df = pd.DataFrame(seq_stats)\n",
    "        seq_stats_df.to_csv(os.path.join(output_folder, f'{dataset}_{sub_folder}_seq_stats.csv'), index=False)\n",
    "\n",
    "    # Aggregate statistics for the entire dataset\n",
    "    overall_mean = np.mean(dataset_mean_values)\n",
    "    overall_max = np.max(dataset_max_values)\n",
    "    overall_min = np.min(dataset_min_values)\n",
    "\n",
    "    all_mean_values.extend(dataset_mean_values)\n",
    "    all_max_values.extend(dataset_max_values)\n",
    "    all_min_values.extend(dataset_min_values)\n",
    "\n",
    "    print(f\"Dataset [{dataset}] overall mean targets per frame: [{overall_mean:.4f}], max targets: [{overall_max:.4f}], min targets: [{overall_min:.4f}]\")\n",
    "\n",
    "    # Save dataset-level statistics to a CSV file\n",
    "    dataset_stats_df = pd.DataFrame({\n",
    "        'mean': dataset_mean_values,\n",
    "        'max': dataset_max_values,\n",
    "        'min': dataset_min_values\n",
    "    })\n",
    "    dataset_stats_df.to_csv(os.path.join(output_folder, f'{dataset}_overall_stats.csv'), index=False)\n",
    "\n",
    "# Compute overall statistics for all datasets\n",
    "final_mean = np.mean(all_mean_values)\n",
    "final_max = np.max(all_max_values)\n",
    "final_min = np.min(all_min_values)\n",
    "\n",
    "print(f\"Overall mean targets per frame: [{final_mean:.4f}], max targets: [{final_max:.4f}], min targets: [{final_min:.4f}]\")\n",
    "\n",
    "# Save overall statistics to a CSV file\n",
    "final_stats_df = pd.DataFrame({\n",
    "    'mean': all_mean_values,\n",
    "    'max': all_max_values,\n",
    "    'min': all_min_values\n",
    "})\n",
    "final_stats_df.to_csv(os.path.join(output_folder, 'final_overall_stats.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = r\"experiments\\statisticalData\\targetCounts\\DanceTrack_val_seq_stats.csv\"  # 替换为你的文件路径\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 提取数据\n",
    "seq = data['seq']\n",
    "mean = data['mean']\n",
    "max_values = data['max']\n",
    "min_values = data['min']\n",
    "\n",
    "# 绘制柱状图\n",
    "x = np.arange(len(seq))  # x轴位置\n",
    "bar_width = 0.25\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - bar_width, mean, width=bar_width, label='Mean', alpha=0.8, color='#6AB7C6')   # Mean 的柱子为蓝色\n",
    "plt.bar(x, max_values, width=bar_width, label='Max', alpha=0.8, color='#FFA07A')       # Max 的柱子为橙色\n",
    "plt.bar(x + bar_width, min_values, width=bar_width, label='Min', alpha=0.8, color='#FFD700') # Min 的柱子为绿色\n",
    "\n",
    "# 添加标签和标题\n",
    "plt.xticks(x, seq, rotation=45)\n",
    "plt.xlabel(\"Sequence (seq)\")\n",
    "plt.ylabel(\"People Count\")\n",
    "plt.title(\"Statistics of People Count per Frame in DanceTrack-val\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.savefig('./.assert/DanceTrack-val.png')\n",
    "# 显示图表\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 绘制不同K下的HOTA曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个包含所有字典的列表\n",
    "KFamily ={\n",
    "    2:[25.29,51.08,12.57,25.02,20.49,32.13,50.01,83.86],\n",
    "    3:[27.29,51.14,14.61,27.84,22.83,35.67,52.56,83.82],\n",
    "    4:[28.87,51.33,16.30,30.06,24.67,38.46,53.53,83.85],\n",
    "    5:[29.87,51.27,17.45,30.59,25.08,39.20,53.46,83.82],\n",
    "    6:[29.25,51.56,16.64,30.33,24.91,38.76,53.76,83.81],\n",
    "    7:[28.79,51.10,16.27,29.28,24.00,37.54,53.00,83.81],\n",
    "    8:[29.86,51.46,17.36,30.80,25.30,39.38,54.10,83.81],\n",
    "    12:[30.33,51.09,18.06,32.34,26.53,41.41,53.21,83.82],\n",
    "    16:[29.99,51.20,17.50,31.74,26.04,40.64,52.63,83.79],\n",
    "    999:[25.40,46.24,13.99,25.89,20.37,35.40,42.60,83.76],\n",
    "}\n",
    "# 创建一个包含所有指标的列表\n",
    "metrics = ['HOTA', 'DetA', 'AssA', 'IDF1', 'IDR', 'IDP']\n",
    "# 创建一个新的figure\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
    "\n",
    "# 绘制HOTA, DetA, AssA的折线图\n",
    "for i, metric in enumerate(metrics):\n",
    "    if i <3:\n",
    "        idx = 0\n",
    "        title = 'HOTA Metrics'\n",
    "    elif 3 <= i < 6:\n",
    "        idx = 1\n",
    "        title = 'Identity Metrics'  \n",
    "    # values =\n",
    "    x , y = [] , [] \n",
    "    for k,v in KFamily.items():\n",
    "        x.append(k)\n",
    "        y.append(v[i])\n",
    "    axs[idx].plot(x,y, marker='o',label = metric)\n",
    "    axs[idx].set_title(title)\n",
    "    axs[idx].set_xlabel('K value')\n",
    "    axs[idx].set_ylabel('Value')\n",
    "    axs[idx].set_xscale('log')\n",
    "    axs[idx].set_xticks(x)\n",
    "# 显示图例\n",
    "for ax in axs.flat:\n",
    "    ax.legend()\n",
    "\n",
    "# 保存图像\n",
    "plt.tight_layout()\n",
    "# plt.savefig('metrics.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个包含所有字典的列表\n",
    "KFamily = {\n",
    "    2: [22.92 , 49.66 , 10.67 , 22.53 , 18.49 , 28.81 , 51.65 , 82.00 ],\n",
    "    3: [24.58 , 49.92 , 12.20 , 25.82 , 21.23 , 32.94 , 51.99 , 81.98],\n",
    "    4: [27.89 , 50.02 , 15.66 , 29.33 , 24.13 , 37.38 , 54.52 , 81.98],\n",
    "    5: [29.58 , 50.14 , 17.56 , 30.84 , 25.40 , 39.26 , 55.35 , 81.95],\n",
    "    6: [30.40, 50.20, 18.54, 32.79, 27.01, 41.70, 55.47 ,81.98],\n",
    "    7: [32.60 , 50.25 , 21.27 , 34.86 , 28.75 , 44.26 , 56.53 , 81.99],\n",
    "    8: [35.09 , 50.05 , 24.75 , 39.01 , 32.14 , 49.61 , 56.89 , 82.00],\n",
    "    12: [33.85 , 50.18 , 22.96 , 37.12 , 30.60 , 47.19 , 56.72 , 82.00],\n",
    "    16: [32.37 , 50.40 , 20.90 , 35.49 , 29.24 , 45.12 , 57.11 , 82.03],\n",
    "    32: [ 36.11 , 50.24 , 26.09 , 40.01 , 32.97 , 50.88 , 56.66 , 82.02 ],\n",
    "    64: [ 35.02 , 50.51 , 24.43 , 38.64 , 31.85 , 49.13 , 56.85 , 82.06 ],\n",
    "    999: [35.02 , 50.51 , 24.43 , 38.64 , 31.85 , 49.13 , 56.85 , 82.06],\n",
    "}\n",
    "\n",
    "# 创建一个包含所有指标的列表\n",
    "metrics = ['HOTA', 'DetA', 'AssA', 'IDF1', 'IDR', 'IDP','MOTA','MOTP']\n",
    "\n",
    "# 创建一个新的figure\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "# 定义 x 的值（K 的值）并排序\n",
    "x = sorted(KFamily.keys())\n",
    "\n",
    "# 绘制每个指标的折线图\n",
    "for i, metric in enumerate(metrics):\n",
    "    if i < 3:\n",
    "        idx = 0\n",
    "        title = 'HOTA Metrics'\n",
    "    elif 3 <= i < 6:\n",
    "        idx = 1\n",
    "        title = 'Identity Metrics'\n",
    "    else:\n",
    "        idx = 2\n",
    "        title = 'MOT Metrics'\n",
    "    # 提取对应的 y 值\n",
    "    y = [KFamily[k][i] for k in x]\n",
    "\n",
    "    # 绘制折线\n",
    "    axs[idx].plot(x, y, marker='o', label=metric)\n",
    "    axs[idx].set_title(title)\n",
    "    axs[idx].set_xlabel('K value')\n",
    "    # axs[idx].set_ylabel('Value')\n",
    "    axs[idx].set_xscale('log')  # 设置为对数刻度\n",
    "\n",
    "    # 设置对数刻度的刻度值\n",
    "    axs[idx].set_xticks(x)\n",
    "    axs[idx].get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "    axs[idx].tick_params(axis='x', rotation=0)  # 旋转刻度标签方便显示\n",
    "\n",
    "# 显示图例\n",
    "for ax in axs.flat:\n",
    "    ax.legend()\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.savefig('.assert/Kfamily_metrics.png')\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "metrics = ['HOTA', 'DetA', 'AssA', 'IDF1', 'IDR', 'IDP','MOTA','MOTP']\n",
    "\n",
    "table = {\n",
    "    35: [43.33         , 50.84 , 37.11 , 51.01 , 42.11 , 64.70 , 59.46 , 81.99],\n",
    "    50: [ 45.19, 50.51 ,40.61 , 52.12 , 43.04 , 66.07 , 59.05 , 81.98],\n",
    "    60: [43.59    , 50.33 , 37.93 , 49.91 , 41.20 , 63.27 , 58.73 , 81.95],\n",
    "    100: [39.72    , 50.34 , 31.53 , 43.74 , 36.11 , 55.45 , 57.71 , 81.92],\n",
    "    150: [37.91    , 50.40 , 28.73 , 40.82 , 33.69 , 51.77 , 57.03 , 81.97],\n",
    "    200: [36.47         , 50.33 , 26.61 , 39.49 , 32.58 , 50.10 , 56.69 , 81.95],\n",
    "    250: [35.09         , 50.26 , 24.69 , 37.80 , 31.18 , 47.99 , 56.26 , 81.98],\n",
    "    300: [34.69    ,50.42, 24.03 ,36.72 ,30.29 ,46.62 ,56.20 ,81.97],\n",
    "    350: [29.33 , 49.58 , 17.47 , 30.08 , 24.72 , 38.42 , 53.06 , 81.91],\n",
    "    400: [31.91   , 50.26 , 20.40 , 33.99 , 28.02 , 43.18 , 55.78 , 81.96],\n",
    "    450: [32.70    ,50.33, 21.38 ,35.12 ,28.96 ,44.63 ,55.77 ,81.97],\n",
    "    500: [32.58 ,50.27, 21.26, 35.16, 28.99, 44.66, 55.90, 81.96],\n",
    "    \"None\": [25.29, 51.08, 12.57, 25.02, 20.49, 32.13, 50.01, 83.86],\n",
    "}\n",
    "\n",
    "\n",
    "# 创建一个新的figure\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 6))\n",
    "\n",
    "# 绘制每个指标的折线图\n",
    "for cnt in range(3):\n",
    "    if cnt == 1:\n",
    "        title = r'Distance Mask '\n",
    "\n",
    "    for i, metric in enumerate(metrics):    \n",
    "        if i < 3:\n",
    "            idx = 0\n",
    "            title = 'HOTA Metrics'\n",
    "        elif 3 <= i < 6:\n",
    "            idx = 1\n",
    "            title = 'Identity Metrics'\n",
    "        else:\n",
    "            idx = 2\n",
    "            title = 'MOT Metrics'\n",
    "        # 提取对应的 y 值\n",
    "        y = [KFamily[k][i] for k in x]\n",
    "\n",
    "        # 绘制折线\n",
    "        axs[cnt,idx].plot(x, y, marker='o', label=metric)\n",
    "        axs[cnt,idx].set_title(title)\n",
    "        axs[cnt,idx].set_xlabel('Mask Value')\n",
    "        # axs[idx].set_ylabel('Value')\n",
    "        axs[cnt,idx].set_xscale('log')  # 设置为对数刻度\n",
    "\n",
    "        # 设置对数刻度的刻度值\n",
    "        axs[cnt,idx].set_xticks(x)\n",
    "        axs[cnt,idx].get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "        axs[cnt,idx].tick_params(axis='x', rotation=0)  # 旋转刻度标签方便显示\n",
    "\n",
    "# 显示图例\n",
    "for ax in axs.flat:\n",
    "    ax.legend()\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.savefig('.assert/Kfamily_metrics.png')\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the issue with x and y lengths and ensuring consistent plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "metrics = ['HOTA', 'DetA', 'AssA', 'IDF1', 'IDR', 'IDP','MOTA','MOTP']\n",
    "\n",
    "table = {\n",
    "    35: [43.33         , 50.84 , 37.11 , 51.01 , 42.11 , 64.70 , 59.46 , 81.99],\n",
    "    50: [ 45.19, 50.51 ,40.61 , 52.12 , 43.04 , 66.07 , 59.05 , 81.98],\n",
    "    60: [43.59    , 50.33 , 37.93 , 49.91 , 41.20 , 63.27 , 58.73 , 81.95],\n",
    "    100: [39.72    , 50.34 , 31.53 , 43.74 , 36.11 , 55.45 , 57.71 , 81.92],\n",
    "    150: [37.91    , 50.40 , 28.73 , 40.82 , 33.69 , 51.77 , 57.03 , 81.97],\n",
    "    200: [36.47         , 50.33 , 26.61 , 39.49 , 32.58 , 50.10 , 56.69 , 81.95],\n",
    "    250: [35.09         , 50.26 , 24.69 , 37.80 , 31.18 , 47.99 , 56.26 , 81.98],\n",
    "    300: [34.69    ,50.42, 24.03 ,36.72 ,30.29 ,46.62 ,56.20 ,81.97],\n",
    "    350: [29.33 , 49.58 , 17.47 , 30.08 , 24.72 , 38.42 , 53.06 , 81.91],\n",
    "    400: [31.91   , 50.26 , 20.40 , 33.99 , 28.02 , 43.18 , 55.78 , 81.96],\n",
    "    450: [32.70    ,50.33, 21.38 ,35.12 ,28.96 ,44.63 ,55.77 ,81.97],\n",
    "    500: [32.58 ,50.27, 21.26, 35.16, 28.99, 44.66, 55.90, 81.96],\n",
    "    \"None\": [25.29, 51.08, 12.57, 25.02, 20.49, 32.13, 50.01, 83.86],\n",
    "}\n",
    "\n",
    "# Clean x to only include integers\n",
    "x = [key for key in table.keys() if isinstance(key, int)]\n",
    "\n",
    "# Function to plot a single table\n",
    "def plot_table(axs, table, title, row):\n",
    "    for i, metric in enumerate(metrics):\n",
    "        y = [table[k][i] for k in table if isinstance(k, int)]  # Filter out non-integer keys\n",
    "        ax = axs[row, i // 3]  # Determine subplot based on metric index\n",
    "        ax.plot(x, y, marker='o', label=metric)  # Use cleaned x\n",
    "        ax.set_title(title if i % 3 == 0 else \"\")  # Set title only for the first metric in the row\n",
    "        ax.set_xlabel('Mask Range')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "# Function to compare two tables\n",
    "def plot_comparison(axs, table1, table2, title, row):\n",
    "    for i, metric in enumerate(metrics):\n",
    "        y1 = [table1[k][i] for k in table1 if isinstance(k, int)]\n",
    "        # y2 = [table2[k][i] for k in table2 if isinstance(k, int)]\n",
    "        ax = axs[ i // 3]\n",
    "        ax.plot(x, y1, marker='o', label=f\"{metric} (with mask)\", linestyle='-')\n",
    "        # ax.plot(x, y2, marker='s', label=f\"{metric} (without mask)\", linestyle='-')\n",
    "        ax.set_title(title if i % 3 == 0 else \"\")\n",
    "        ax.set_xlabel('Mask Range')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 8))\n",
    "\n",
    "# First row: Table 1\n",
    "# plot_table(axs, table, \"Table 1 Metrics (Trained with Distance Mask)\", 0)\n",
    "\n",
    "# # Second row: Table 2\n",
    "# plot_table(axs, table_2, \"Table 2 Metrics (Trained without Distance Mask)\", 1)\n",
    "\n",
    "# Third row: Comparison\n",
    "plot_comparison(axs, table, None, \"Comparison Between Table 1 and Table 2\", 0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig('.assert/mask.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 伪造只有一个物体的图，看看图卷积输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "#  num_nodes 为1 的特殊情况 只在检测器中检测到\n",
    "#---------------------------------#\n",
    "import cv2\n",
    "path = r'datasets\\eval_datasets\\gt\\mot_challenge\\MOT17-half\\MOT17-13\\img1\\000093.jpg'\n",
    "bbox = (99, 571, 81, 179) # SDP\n",
    "img = cv2.imread(path)\n",
    "cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 8)\n",
    "\n",
    "# 显示图片\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(r'experiments\\single(93-MOT17-13).png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.io.image as I\n",
    "from torch_geometric.data import Data\n",
    "import torchvision.transforms.functional as T\n",
    "\n",
    "\n",
    "path = r'datasets\\eval_datasets\\gt\\mot_challenge\\MOT17-half\\MOT17-13\\img1\\000093.jpg'\n",
    "bbox = (99, 571, 81, 179) # SDP\n",
    "\n",
    "im_tensor = I.read_image(path)\n",
    "img_tensor  = im_tensor.to(torch.float32) / 255.0\n",
    "raw_node_attr , location_info = [] , []\n",
    "im_tensor = T.normalize(img_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "x , y , w , h = map(int, bbox)\n",
    "xc , yc   = x + w/2 , y + h/2\n",
    "x2 , y2   = x + w   , y + h\n",
    "if x < 0:\n",
    "    w = w + x  \n",
    "    x = 0 \n",
    "\n",
    "if y < 0:\n",
    "    h = h + y  \n",
    "    y = 0  \n",
    "    \n",
    "w = min(w, im_tensor.shape[2] - x)  \n",
    "h = min(h, im_tensor.shape[1] - y)\n",
    "\n",
    "patch = T.crop(im_tensor,y,x,h,w)\n",
    "patch = T.resize(patch,[256,128])\n",
    "raw_node_attr.append(patch)\n",
    "location_info.append([x,y,x2,y2,w,h,xc,yc])\n",
    "\n",
    "raw_node_attr = torch.stack(raw_node_attr,dim=0)\n",
    "location_info = torch.as_tensor(location_info,dtype=torch.float32)\n",
    "sigle_graph = Data(x=raw_node_attr,location_info=location_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "# 加载模型\n",
    "#---------------------------------#\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#---------------------------------#\n",
    "#  load  configs and checkpoint \n",
    "#---------------------------------#\n",
    "import torch\n",
    "from configs.config import get_config\n",
    "from models.graphModel import GraphModel\n",
    "from utils.graphDataset import GraphDataset\n",
    "cfg = get_config()\n",
    "\n",
    "model = GraphModel(cfg.MODEL_YAML_PATH)\n",
    "checkpoint = torch.load(r'model_weights\\DA_120epoch.pth',map_location='cpu')\n",
    "model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "#  Node Encoder \n",
    "#---------------------------------#\n",
    "sigle_graph_model =  model.nodeEncoder(sigle_graph.clone())\n",
    "sigle_graph, sigle_graph_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------#\n",
    "# Edge Encoder\n",
    "#---------------------------------#\n",
    "sigle_graph_model = model.edgeEncoder(sigle_graph_model,model.k)\n",
    "sigle_graph_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigle_graph_model.edge_index,sigle_graph_model.edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 计算FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\2torch1.8\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[Validation] Data-preprocess: 100%|██████████| 1/1 [00:00<00:00,  2.07dataset/s]\n",
      "\u001b[32m2025-01-06 21:53:53.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.graphDataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1m[Validation] Total frame number : 2652\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------#\n",
    "#  载入数据\n",
    "#---------------------------------#\n",
    "\n",
    "#---------------------------------#\n",
    "#  预备工作：\n",
    "#  导入库\n",
    "#  加载配置文件\n",
    "#  加载模型，加载数据集\n",
    "#---------------------------------#\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#---------------------------------#\n",
    "#  load  configs and checkpoint \n",
    "#---------------------------------#\n",
    "import torch\n",
    "from configs.config import get_config\n",
    "from models.graphModel import GraphModel\n",
    "from utils.graphDataset import GraphDataset\n",
    "cfg = get_config()\n",
    "\n",
    "cfg.JSON_PATH = r'configs\\train_MOT17.json'\n",
    "test_dataset = GraphDataset(cfg,'Validation',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_graph , det_graph , _= test_dataset.__getitem__(2120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                                       | #parameters or shape   | #flops     |\n",
      "|:---------------------------------------------|:-----------------------|:-----------|\n",
      "| model                                        | 9.851M                 | 29.98G     |\n",
      "|  alpha                                       |  (1,)                  |            |\n",
      "|  eplison                                     |  (1,)                  |            |\n",
      "|  nodeEncoder                                 |  7.654M                |  29.943G   |\n",
      "|   nodeEncoder.backbone.0                     |   6.954M               |   29.931G  |\n",
      "|    nodeEncoder.backbone.0.conv0              |    9.408K              |    1.233G  |\n",
      "|    nodeEncoder.backbone.0.norm0              |    0.128K              |    16.777M |\n",
      "|    nodeEncoder.backbone.0.denseblock1        |    0.335M              |    10.979G |\n",
      "|    nodeEncoder.backbone.0.transition1        |    33.28K              |    1.091G  |\n",
      "|    nodeEncoder.backbone.0.denseblock2        |    0.92M               |    7.534G  |\n",
      "|    nodeEncoder.backbone.0.transition2        |    0.132M              |    1.082G  |\n",
      "|    nodeEncoder.backbone.0.denseblock3        |    2.838M              |    5.812G  |\n",
      "|    nodeEncoder.backbone.0.transition3        |    0.526M              |    1.078G  |\n",
      "|    nodeEncoder.backbone.0.denseblock4        |    2.158M              |    1.105G  |\n",
      "|    nodeEncoder.backbone.0.norm5              |    2.048K              |    1.049M  |\n",
      "|   nodeEncoder.head                           |   0.7M                 |   11.73M   |\n",
      "|    nodeEncoder.head.1.layers                 |    0.7M                |    11.206M |\n",
      "|    nodeEncoder.head.0.1                      |                        |    0.524M  |\n",
      "|  edgeEncoder.encoder.layers                  |  0.4K                  |  19.2K     |\n",
      "|   edgeEncoder.encoder.layers.0               |   80                   |   3.84K    |\n",
      "|    edgeEncoder.encoder.layers.0.weight       |    (16, 5)             |            |\n",
      "|   edgeEncoder.encoder.layers.1               |   32                   |   1.536K   |\n",
      "|    edgeEncoder.encoder.layers.1.weight       |    (16,)               |            |\n",
      "|    edgeEncoder.encoder.layers.1.bias         |    (16,)               |            |\n",
      "|   edgeEncoder.encoder.layers.3               |   0.256K               |   12.288K  |\n",
      "|    edgeEncoder.encoder.layers.3.weight       |    (16, 16)            |            |\n",
      "|   edgeEncoder.encoder.layers.4               |   32                   |   1.536K   |\n",
      "|    edgeEncoder.encoder.layers.4.weight       |    (16,)               |            |\n",
      "|    edgeEncoder.encoder.layers.4.bias         |    (16,)               |            |\n",
      "|  graphconvLayer                              |  2.196M                |  36.975M   |\n",
      "|   graphconvLayer.sg1conv                     |   7.424K               |   0.221M   |\n",
      "|    graphconvLayer.sg1conv.msg_func.layers    |    3.2K                |    0.154M  |\n",
      "|    graphconvLayer.sg1conv.update_func.layers |    4.224K              |    67.584K |\n",
      "|   graphconvLayer.sg2conv                     |   17.28K               |   0.528M   |\n",
      "|    graphconvLayer.sg2conv.msg_func.layers    |    7.872K              |    0.378M  |\n",
      "|    graphconvLayer.sg2conv.update_func.layers |    9.408K              |    0.151M  |\n",
      "|   graphconvLayer.sg3conv                     |   31.232K              |   0.967M   |\n",
      "|    graphconvLayer.sg3conv.msg_func.layers    |    14.592K             |    0.7M    |\n",
      "|    graphconvLayer.sg3conv.update_func.layers |    16.64K              |    0.266M  |\n",
      "|   graphconvLayer.dg1conv.msg_func.layers     |   21.888K              |   0.7M     |\n",
      "|    graphconvLayer.dg1conv.msg_func.layers.0  |    12.288K             |    0.393M  |\n",
      "|    graphconvLayer.dg1conv.msg_func.layers.1  |    0.192K              |    6.144K  |\n",
      "|    graphconvLayer.dg1conv.msg_func.layers.3  |    9.216K              |    0.295M  |\n",
      "|    graphconvLayer.dg1conv.msg_func.layers.4  |    0.192K              |    6.144K  |\n",
      "|   graphconvLayer.dg2conv.msg_func.layers     |   41.472K              |   1.327M   |\n",
      "|    graphconvLayer.dg2conv.msg_func.layers.0  |    24.576K             |    0.786M  |\n",
      "|    graphconvLayer.dg2conv.msg_func.layers.1  |    0.256K              |    8.192K  |\n",
      "|    graphconvLayer.dg2conv.msg_func.layers.3  |    16.384K             |    0.524M  |\n",
      "|    graphconvLayer.dg2conv.msg_func.layers.4  |    0.256K              |    8.192K  |\n",
      "|   graphconvLayer.fuse1conv.layers            |   0.526M               |   8.421M   |\n",
      "|    graphconvLayer.fuse1conv.layers.0         |    0.524M              |    8.389M  |\n",
      "|    graphconvLayer.fuse1conv.layers.1         |    2.048K              |    32.768K |\n",
      "|   graphconvLayer.fuse2conv.layers            |   1.551M               |   24.809M  |\n",
      "|    graphconvLayer.fuse2conv.layers.0         |    1.18M               |    18.874M |\n",
      "|    graphconvLayer.fuse2conv.layers.1         |    1.536K              |    24.576K |\n",
      "|    graphconvLayer.fuse2conv.layers.3         |    0.295M              |    4.719M  |\n",
      "|    graphconvLayer.fuse2conv.layers.4         |    0.768K              |    12.288K |\n",
      "|    graphconvLayer.fuse2conv.layers.6         |    73.728K             |    1.18M   |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "from models.graphModel import TrainingGraphModel, GraphModel\n",
    "\n",
    "# Example of loading your model\n",
    "# model_yaml_path = 'path_to_your_model_yaml.yaml'  # Update this path\n",
    "model = GraphModel(cfg.MODEL_YAML_PATH)  # You can switch to GraphModel if required\n",
    "\n",
    "# Dummy inputs for the model\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "# checkpoint = torch.load(r'model_weights\\DA_120epoch.pth',map_location='cpu')\n",
    "# model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "# Create example input data compatible with your model\n",
    "# Make sure to adjust these inputs based on your actual graph data\n",
    "model.eval()\n",
    "# Convert Data objects to tuples of tensors\n",
    "def graph_to_tuple(graph):\n",
    "    return (graph.x, graph.edge_index,graph.location_info)\n",
    "\n",
    "tra_tuple = graph_to_tuple(tra_graph)\n",
    "det_tuple = graph_to_tuple(det_graph)\n",
    "\n",
    "# Custom wrapper to adapt the forward pass of the model\n",
    "class FLOPSWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, tra_tuple, det_tuple):\n",
    "        # Reconstruct Data objects from tuples for forward pass\n",
    "        tra_graph = Data(x=tra_tuple[0], edge_index=tra_tuple[1],location_info=tra_tuple[2])\n",
    "        det_graph = Data(x=det_tuple[0], edge_index=det_tuple[1],location_info=det_tuple[2])\n",
    "        return self.model(tra_graph, det_graph)\n",
    "# Wrap the model\n",
    "wrapped_model = FLOPSWrapper(model)\n",
    "\n",
    "# Calculate FLOPS\n",
    "try:\n",
    "    flops = FlopCountAnalysis(wrapped_model, (tra_tuple, det_tuple))\n",
    "    print(flop_count_table(flops))\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating FLOPS: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors = [ '#99ff99', '#ffcc99', '#c2c2f0']\n",
    "# Define the new components and their corresponding FLOPS (GigaFLOPS)\n",
    "components = [\n",
    "    \"node Encoder\",\n",
    "    # \"edge Encoder\",\n",
    "    \"SDGCN\",\n",
    "    # \"Dynamic GCN\",\n",
    "    \"Fuse Model\"\n",
    "]\n",
    "flops_new = [\n",
    "    29.943,        # FLOPS for nodeEncoder (in GFLOPS)\n",
    "    # 0.0192,        # FLOPS for edgeEncoder (in GFLOPS)\n",
    "    # 0.001716,      # FLOPS for sgconv (sum of sg1conv, sg2conv, sg3conv)\n",
    "    3.306,         # FLOPS for dgconv (sum of dg1conv and dg2conv)\n",
    "    33.23          # FLOPS for fuse (sum of fuse1conv and fuse2conv)\n",
    "]\n",
    "\n",
    "# Plotting the updated pie chart with 5 components\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(flops_new, labels=components, autopct='%1.1f%%', startangle=140,colors=colors,wedgeprops={'edgecolor': 'black'},textprops={'fontsize': 18}, )\n",
    "plt.title(\"FLOPS Distribution Across Model Components\", fontsize=20, fontweight='bold')\n",
    "plt.savefig('.assert/FLOPS(VanillaModel).png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the components and their corresponding parameter counts (in millions)\n",
    "components_params = [\n",
    "    \"node Encoder\",\n",
    "    \"SDGCN\",\n",
    "    \"Fuse Model\"\n",
    "]\n",
    "params_new = [\n",
    "    7.654,  # Parameters for nodeEncoder (in millions)\n",
    "    2.236,  # Parameters for SDGCN (graphconvLayer)\n",
    "    2.077   # Parameters for Fuse Model (sum of fuse1conv and fuse2conv)\n",
    "]\n",
    "\n",
    "# Colors for the chart\n",
    "colors_params_blue = ['#66b3ff', '#3399ff', '#99ccff']\n",
    "colors_params = ['#ff9999', '#99ff99', '#ffcc99']\n",
    "# Plotting the parameter distribution pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    params_new,\n",
    "    labels=components_params,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=140,\n",
    "    colors=colors_params,\n",
    "    wedgeprops={'edgecolor': 'black'},\n",
    "    textprops={'fontsize': 18}\n",
    ")\n",
    "plt.title(\"Parameter Distribution Across Model Components\", fontsize=20, fontweight='bold')\n",
    "plt.savefig('.assert/Parms(VanillaModel).png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2torch1.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
